# 1. Introduction to Power Platform & App Scenario

Power Platform is the low code platform from Microsoft. If required also coding is possible e.g. by providing JavaScript. The Microsoft cloud service Azure is the foundation of the platform. This primer won't cover all aspects of the platform. It focuses at the aspects that are important for this hackathon.

# 2. Introduction to Power Platform
## Web portal of Power Platform

The most important tool from the hackathon perspective is the web portal. It allows you to work with all relevant components for our hackathon such as the Dataverse, Power Apps and solutions. The portal is scoped to a certain environment. A PowerPlatform environment represents an environment such as dev or prod as you know it from software engineering. PowerPlatform environment types are for instance sandbox or production. The picture below shows a screenshot of the portal.

<br><img src="./images/intro_power_platform.png" /><br>

Cooments regarding the picture:
* The red boxes in the picture mark the environment and the user.
* On the left hand side you have the main navigation that allows you to reach Dataverse, Power Apps and solutions.
* Make sure you are always LOGGED IN with the user we provide in the hackathon and not with your Capgemini EMail account

## Dataverse

Dataverse is the built-in persistence mechanism for Power Platform. It is designed for transactional data. For analytic worloads Microsoft recommends switching to Azure. The core service is a SQL server but as you can see in the picture Dataverse is a implemented behind the sceen by a bunch of services.

<br><img src="./images/intro_dataverse.png" /><br>

The central element for storing data are tables. A table is just another entity in Power Platform as for instance a Power App. Columns, keys, views and relationships are compareable to the counterparts in relational databses. The following points summarize power platform concepts starting from relational database counterparts:

* **Custom table:** Is a table that you define on top on the existing ones defined by the system such as "account". For our hackathon we use only custom tables without reusing existing ones.
* **Predefined columns:** A newly created custom table comes with a lot of predefined columns.
* **Primary Key:** Power Platform differentiates between the primary key that you name and an internal id (GUID). We will hit a scenario where we will need the internal GUID for referencing a record.
* **Keys:** Unique constraints for one or multiple columns can be modelled via keys.
* **Business Rules:** The allow to model constraints in general such as limiting vaues to a certain range. 
* **Autogenerated values:** In power platform you don't have separate sequence objects but you can specify the value as autogenerated according to a certain pattern.
* **Relationships:** They correspond to foreign key constraints in relational databases. Power platform uses partially a special terminology. An example are lookup columns that boil down to a relationship under the hood.
* **Choices:** You can think of them as an enum or a table with key value pairs. Relational databases don't provide something like that out of the box. You can limit a column to these values by associating the column with the choice as part of the column definition.

## Model-driven-Apps

Model driven apps are a special application type within power apps. Besides you have:
* Portal pages
* Canvas
A discussion of these types beyond the scope of this hackathon.

Model driven apps consist of a number of pages. Each page can use one of the three technologies which greatly differ from the developer experience:
1. Based on dataverse tables
2. Custom Pages (Our focus)
3. Dashboards
These three options are also reflected by the main choice you have to make when adding a page:

<br><img src="./images/intro_apps_page_types.png" /><br>

Custom pages can give you a citizen developer like experience. Compared to  the dataverse table option they are closer to architecture principles for professional developers since the UI is not directly bound to the tables. However unexpected shortcomings were identified during that hackathon and the licensing is still per user. Only power pages provide licenses that are for a bunch of users.

Editing custom pages is a two step process. First you switch the Model-driven-app in edit mode. Then you select the page to be edited.

<br><img src="./images/intro_app_stepwise_edit.png" /><br>

Changing something is also a two step process. They must be saved AND published to take effect. First then you see changes for a certain custom page also in the application screen. The picture below shows the icons for svaing and publishing:

<br><img src="./images/intro_app_save_publish.png" /><br>

## Power Automate

Power automate propagates a workflow like business logic programming style that boils down to a graph. The trigger is the starting point, actions are represented by boxes and the lines between the boxes determine what comes next. Access to data sources or third party systems is provided by connectors that are used by the actions under the hood. The picture below shows a simple example of a few sequential steps:

<br><img src="./images/intro_flows_example.png" /><br>

Comments regarding the picture:
* Trigger of the flow is a Power App
* The flow uses variables to transport information all the way down to the end
* The action "Add Row" adds a row to the specified dataverse table. It is an example that uses a connector under the hood.

There are various types of flows but the major distinction for us is the following:
1. Stand alone flow that is defined in Power Automate
2. Flow that is embedded in a Power App
We will use the second option since option one requires higher licenses.

## Solutions

The standard way to program in a low code platform is rather clicking instead of coding. That is fine for dev/ test environments. But think of production as environment. There clicking together is no option. You rather want to transfer what you clicked together as it is to production. That requires a programmatic way to export something from your dev/ test environment and import it to production.

The vehicle is a solution which can transport any artefact from power platform. You can click it together in the portal or by exporting it. Exporting a solution gives you a zip file. The reverse operation reinstates the objects you exported in the designated environment. We will use that mechanism to quickly provision your environment with th fully implemented data model and the partially implemented application.

# 3. Application Scenario

## Business Problem

Our application is centeredaround CO2 consumption data that is uploaded by the user. Once the upload is final it must be approved. First then it appears in the final destination table that holds the accumulated CO2 consumption per year. Importing consumption data consists of two parts:
* Import Header

  The header summarizes an import. It contains important general importing and approving details such as user and timestamps. Business rules enforce consistency e.g. an approving user must be stored if the state is approved. One tracks the current state of the import which has the following state model:
  
  * Pending - Import has been done but the figures are not ready for approval
  * Finalized - Figures are ready for approval
  * Approved - Figures habe been approved and can be processed
  * Processed - Figures have been added to the accumated CO2 consumption by the system.

* Import data

  Each record in the table denotes a CO2 consumption. Driver refers to the substance that caused the CO2 emission.

## Application Functionality

Our application knows two types of users:
* Users that are eligible for import (all employees that are not part of the COMPLIANCE department)
* Users that are eligible for approval (all employees that are  part of the COMPLIANCE department)
The application will internally track the user type by a sign in process that we already implemented for you.

The application provides importing users a search mask as entry point. It contains the list of imports with the possibility to filter. The screenshots below are not the final ones from the programmed application (e.g. a more professional look and feel is missing). They are conceptual ones that shall just better explain which functionality is provided per screen:

<br><img src="./images/intro_apps_imp_mask_ovr.png" /><br>

It allows the user to either
* Start a new import or
* Editing an existing one as long as the import is not yet finalized

Major mechanism to manage the import is a wizard. The context of the wizard is either (1) the import to be edited or (2) creating a new one. that consists of three steps:
* Create/ Update - Creates/ updates the header depending on the wizard context

  This step is only intended for the importing user. If the approver navigates to that screen all controls are disabled. For simplicity reasons the newly created header will be written directly to the dataverse when submit is clicked. The screenshot below shows the conceptual screen:
  <br><img src="./images/intro_apps_imp_mask_wiz_cre.png" /><br>

* Upload - Uploads the local file containing the consumption data

  This step is only intended for the importing user. If the approver navigates to that screen all controls are disabled. The upload will always refer to an existing import. Either the header import from the wizard context is edited or the newly created one. The screenshot below shows the conceptual screen:
  <br><img src="./images/intro_apps_imp_mask_wiz_upl.png" /><br>

* Approve - This step depends is intended ofr importing ad approving user alike.

  If the importer clicks the `approve` button the import header is set to finalized. The same click from the approver sets the header to `approved` what starts the taking over to the final table. The screenshot below shows the conceptual screen:
  <br><img src="./images/intro_apps_imp_mask_wiz_appr.png" /><br>

The approving user also gets a search mask as entry point that is geared towards finalized imports that have not been approved yet. Approval is done by directly jumping to the third step of the wizard based on the selected import. Additionally the approver can display the accumulated CO2 consumptions per year.

<br><img src="./images/intro_apps_appr_mask_ovr.png" /><br>
<br><img src="./images/intro_apps_appr_mask_co2_cons.png" /><br>

Our application does not provide functionality to maintain users and their corresponding departments. The idea is to use the built-in dataverse functionality to modify the data if required.

## Data Model

The picture below shows the data model:

<br><img src="./images/intro_dataverse_app_model.png" /><br>

The table meaning is as follows:
* IMP_CO2_CONS_ACC - Aggregated C=2 consumption
* IMP_CO2_CONS_RAW_HDR - Import
* IMP_CO2_CONS_RAW - Consumption data
* IMP_USERS - Users and associated department
* IMP_DEARTMENTS - Departments
* IMP_STATES_CHOICE - Eligible import states
* IMP_CO2_DRIVER_TYPES_CHOICE - Drivers for CO2 emission
